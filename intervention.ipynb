{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertForMaskedLM, BertTokenizer, BertConfig\n",
    "import transformers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_from_specific_layer(model: transformers.BertModel, layer_number: int, \n",
    "                                layer_representation: torch.Tensor):\n",
    "    \"\"\"\n",
    "   :param model: a BertForMaskedLM model\n",
    "   :param layer_representation: a torch tensor, dims: [1, seq length, 768]\n",
    "   Return:\n",
    "           states, a numpy array. dims: [#LAYERS - layer_number, seq length, 768]\n",
    "           last_state_after_batch_norm: np array, after batch norm. dims: [seq_length, 768]\n",
    "   \"\"\"\n",
    "\n",
    "    \n",
    "    layers = model.bert.encoder.layer[layer_number:]\n",
    "    layers.append(model.cls.predictions.transform)\n",
    "\n",
    "    h = layer_representation\n",
    "    states = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, layer in enumerate(layers):\n",
    "            h = layer(h)[0] if i != len(layers) - 1 else layer(h)\n",
    "            states.append(h)\n",
    "\n",
    "    for i, s in enumerate(states):\n",
    "        states[i] = s.detach().cpu().numpy()\n",
    "\n",
    "    states = np.array(states)\n",
    "    for x in states:\n",
    "        assert len(x.shape) == 3\n",
    "\n",
    "    return states.squeeze(1)\n",
    "\n",
    "\n",
    "def intervene_in_layer(model: transformers.BertModel, tokens: torch.Tensor, layer_number: int, \n",
    "                       projection_matrix: torch.tensor, apply_on_all=True):\n",
    "    \"\"\"\n",
    "    Intervening in the representations at layer layer_number.\n",
    "    :param model: a bert model\n",
    "    :layer_number: the layer on which we intervene.\n",
    "    :param projection_matrix\n",
    "    :param apply_on_all: if True, apply projection on all tokens. O/w, apply on the CLS only.\n",
    "    Returns: the all hidden representations of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract representation at layer i\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens, return_dict = True)\n",
    "    hidden_states = outputs[\"hidden_states\"]\n",
    "    hidden_state_layer_i = hidden_states[layer_number][0]\n",
    "    if apply_on_all:\n",
    "        \n",
    "        hidden_state_layer_i = hidden_state_layer_i @ projection_matrix\n",
    "    else:\n",
    "        hidden_state_layer_i[0] = hidden_state_layer_i[0] @ projection_matrix\n",
    "    \n",
    "    # continue the forward pass\n",
    "    hidden_state_layer_i = hidden_state_layer_i.unsqueeze(0) # add empty batch dim\n",
    "    hidden_after_projection_i_onwards = forward_from_specific_layer(model, layer_number, hidden_state_layer_i)\n",
    "    hidden_states_until_i = torch.stack(hidden_states[:layer_number]).squeeze(1)\n",
    "    hidden_states_after_projection = torch.cat([hidden_states_until_i, torch.tensor(hidden_after_projection_i_onwards)])\n",
    "    return hidden_states_after_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states = True)\n",
    "bert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\", config = config)\n",
    "tokens = torch.tensor([tokenizer.encode(\"To be or not to be, that is the question.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 14, 768])\n"
     ]
    }
   ],
   "source": [
    "P = torch.randn(768, 768)\n",
    "states = intervene_in_layer(bert, tokens, 3, P, apply_on_all = True)\n",
    "print(states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
